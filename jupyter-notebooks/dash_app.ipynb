{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dash_app.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install jupyter-dash\n",
        "! pip install morfeusz2"
      ],
      "metadata": {
        "id": "Bk81YN1D8UDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash\n",
        "from dash import dcc\n",
        "from dash import html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import morfeusz2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from joblib import load\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization\n",
        "drive.mount('/content/drive') "
      ],
      "metadata": {
        "id": "C5YP3tWi8TEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25d2a63a-e338-4a4a-8c2e-da3eb21421a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def strip_punctuation(text):\n",
        "#     return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def strip_non_alphanumeric(text):\n",
        "    reg = re.compile('[^a-zA-ZĄąĆćĘęŁłŃńÓóŚśŹźŻż]')\n",
        "    return reg.sub(' ', text)\n",
        "\n",
        "def replace_whitespace(text):\n",
        "    reg = re.compile('\\s+')\n",
        "    return reg.sub(' ', text)\n",
        "\n",
        "def delete_escape_chars(text):\n",
        "    return text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\r', ' ')\n",
        "\n",
        "def delete_stop_words(text):\n",
        "    stop_words_txt = open('drive/MyDrive/Fake News Detection/data/polish.stopwords.txt')\n",
        "    stop_words = stop_words_txt.read().split('\\n')\n",
        "    stop_words_txt.close()\n",
        "    return [word for word in text if word not in stop_words]\n",
        "\n",
        "def preprocess(df):\n",
        "    # df['Text'] = df['Text'].apply(strip_punctuation)\n",
        "    df['Text'] = df['Text'].apply(strip_non_alphanumeric)\n",
        "    df['Text'] = df['Text'].apply(replace_whitespace)\n",
        "    df['Text'] = df['Text'].apply(delete_escape_chars)\n",
        "    df['Text'] = df['Text'].apply(str.lower)\n",
        "    df['Text'] = df['Text'].apply(str.split)\n",
        "    df['Text'] = df['Text'].apply(delete_stop_words)\n",
        "    return df\n",
        "\n",
        "def lemmatise(df):\n",
        "    morf = morfeusz2.Morfeusz()\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['Text']\n",
        "        lemm_words = []\n",
        "        for word in text:\n",
        "            _, _, interpretation = morf.analyse(word)[0]\n",
        "            lem_word = interpretation[1]\n",
        "            lem_word_stripped = lem_word.split(':', 1)[0].lower()\n",
        "            lemm_words.append(lem_word_stripped)\n",
        "        df.loc[index, 'Text'] = ' '.join(lemm_words)\n",
        "    return df"
      ],
      "metadata": {
        "id": "WN79mruCtY4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "32P8BAL36V4d",
        "outputId": "e32b06f9-b34f-4784-e32a-ceb56ce329d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "example = '''\n",
        "Najnowsze dane z raportu brytyjskiej Agencji Bezpieczeństwa Zdrowia \n",
        "(UKHSA) jak i Public Health Scotland, instytucji nadzorujących szczepienia \n",
        "przeciwko COVID-19 pokazują, że stosunek umieralności z powodu koronawirusa z \n",
        "Wuhan jest, jak jedna osoba „niezaszczepiona” do prawie pięć osób „w pełni \n",
        "zaszczepionych”. Z podanych informacji widać, że zdecydowana większość \n",
        "zgłoszonych zgonów ​​ma miejsce po otrzymaniu zastrzyków. Te informacje są \n",
        "wyraźnie sprzeczne z podawanymi przez producentów szczepionek, o ich rzekomej \n",
        "ich skuteczności i 90% wskaźniku zapobiegania śmiertelności, jak i \n",
        "rozpowszechnianą propagandą przez media i rządy poszczególnych państw. W związku \n",
        "z zaistniałą sytuacją angielskie media The Exposé zadały pytanie: „Jeśli \n",
        "zastrzyk Covid ma być w 90% skuteczny w zapobieganiu śmierci, dlaczego \n",
        "„zaszczepieni” ludzie obecnie umierają w stosunku 4,8:1 do „nieszczepionych” \n",
        "osób?”\n",
        "\n",
        "Wniosek – UKHSA kłamie publicznie twierdząc, że szczepionki ratują życie, co \n",
        "jest sprzeczne z tym, co mówią podawane przez nich dane. Kłamią również inne \n",
        "instytucje, media jak i rządy promujące ten specyfik. Korzystając z danych VSR \n",
        "(Vaccine Surveillance Report) zebranych przez okres trzech miesięcy, The Exposé \n",
        "odkrył, że nie tylko odporność ludzi po zaszczepieniu na wrażego chińskiego \n",
        "wirusa spadła, ale również wyjątkowo szybko zanika odporność, która rzekomo \n",
        "jest wytwarzana ludiom przez te zastrzyki.\n",
        "'''\n",
        "\n",
        "# Load Data\n",
        "df = px.data.tips()\n",
        "# Build App\n",
        "app = JupyterDash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H1('Wklej tekst i sprawdź jego wiarygodność!'),\n",
        "    html.Hr(),\n",
        "\n",
        "    html.Div([\n",
        "        dcc.Textarea(\n",
        "            id='input_text',\n",
        "            value=example,\n",
        "            style={'width': '100%', 'height': 200}\n",
        "        ),\n",
        "        html.Br(),\n",
        "        # html.Button('Lematyzuj:', id='lem_button'),\n",
        "        # html.Div(id='lem_text'),\n",
        "\n",
        "        html.Button('Weryfikuj', id='ver_button'),\n",
        "        html.Table([\n",
        "            html.Tr([html.Td(['Klasyfikator NB:']), html.Td(id='NB')]),\n",
        "            html.Tr([html.Td(['Klasyfikator SVC:']), html.Td(id='SVC')]),\n",
        "            html.Tr([html.Td(['Klasyfikator RF:']), html.Td(id='RF')])\n",
        "            \n",
        "        ], style={'font-size': 26})\n",
        "    ]),\n",
        "\n",
        "])\n",
        "# @app.callback(\n",
        "#     Output(component_id='lem_text', component_property='children'),\n",
        "#     Input(component_id='lem_button', component_property='n_clicks'),\n",
        "#     State(component_id='input_text', component_property='value')\n",
        "# )\n",
        "# def lemmatize_text(n_clicks, text):\n",
        "#     if n_clicks > 0:\n",
        "#         text = strip_punctuation(text)\n",
        "#         text = strip_non_alphanumeric(text)\n",
        "#         text = replace_whitespace(text)\n",
        "#         text = delete_escape_chars(text)\n",
        "#         text = str.lower(text)\n",
        "#         text = str.split(text)\n",
        "#         text = delete_stop_words(text)\n",
        "\n",
        "#         morf = morfeusz2.Morfeusz()\n",
        "#         lemm_words = []\n",
        "#         for word in text:\n",
        "#             _, _, interpretation = morf.analyse(word)[0]\n",
        "#             lem_word = (list(interpretation)[1]).lower()\n",
        "#             lem_word_stripped = lem_word.split(':', 1)[0]\n",
        "#             lemm_words.append(lem_word_stripped)\n",
        "#         return f'{lemm_words}'\n",
        "#     else:\n",
        "#         return ''\n",
        "\n",
        "@app.callback(\n",
        "    [\n",
        "        Output(component_id='NB', component_property='children'),\n",
        "        Output(component_id='SVC', component_property='children'),\n",
        "        Output(component_id='RF', component_property='children')\n",
        "    ],\n",
        "    Input(component_id='ver_button', component_property='n_clicks'),\n",
        "    State(component_id='input_text', component_property='value')\n",
        ")\n",
        "def verificate_text(n_clicks, text):\n",
        "    if n_clicks > 0:\n",
        "        df = pd.DataFrame([[text]], columns=['Text'])\n",
        "\n",
        "        df = preprocess(df)\n",
        "        df = lemmatise(df)\n",
        "\n",
        "        # morf = morfeusz2.Morfeusz()\n",
        "        # lemm_words = []\n",
        "        # for word in text:\n",
        "        #     _, _, interpretation = morf.analyse(word)[0]\n",
        "        #     lem_word = (list(interpretation)[1]).lower()\n",
        "        #     lem_word_stripped = lem_word.split(':', 1)[0]\n",
        "        #     lemm_words.append(lem_word_stripped)\n",
        "        \n",
        "        tfidf_vectorizer = load('tfidf.joblib')\n",
        "        tfidf_input = tfidf_vectorizer.transform(df['Text'])\n",
        "\n",
        "        nb_classifier = load('nb_classifier.joblib')\n",
        "        svc_classifier = load('svc_classifier.joblib') \n",
        "        rf_classifier = load('rf_classifier.joblib') \n",
        "\n",
        "        nb_result = str(nb_classifier.predict(tfidf_input)[0])\n",
        "        svc_result = str(svc_classifier.predict(tfidf_input)[0])\n",
        "        rf_result = str(rf_classifier.predict(tfidf_input)[0])\n",
        "\n",
        "        return nb_result, svc_result, rf_result\n",
        "    else:\n",
        "        return '', '', ''\n",
        "# Run app and display result inline in the notebook\n",
        "app.run_server(mode='inline')"
      ]
    }
  ]
}