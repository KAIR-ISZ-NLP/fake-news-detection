{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "S5l74exVP1hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install polyglot\n",
        "! pip install pyicu     # polyglot requirement\n",
        "! pip install Morfessor # polyglot requirement\n",
        "! pip install pycld2    # polyglot requirement\n",
        "! pip install morfeusz2"
      ],
      "metadata": {
        "id": "ucLD45TBjvv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from polyglot.detect import Detector\n",
        "from polyglot.downloader import downloader\n",
        "import re\n",
        "import morfeusz2\n",
        "from typing import List\n",
        "\n",
        "downloader.download('LANG:pl')"
      ],
      "metadata": {
        "id": "nXaqUM5ekEck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aET8QYDqhTvt"
      },
      "outputs": [],
      "source": [
        "def drop_title_and_url(df):\n",
        "    \"\"\"Drops 'Title' and 'Url' columns.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.Dataframe: News dataset without 'Title' and 'Url' columns.\n",
        "    \"\"\"\n",
        "    return df.drop(columns=['Title', 'Url'])\n",
        "\n",
        "\n",
        "def drop_empty(df):\n",
        "    \"\"\"Drops empty rows.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset.\n",
        "\n",
        "    Returns:\n",
        "        df (pd.Dataframe): News dataset without empty rows.\n",
        "    \"\"\"\n",
        "    df.dropna(inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def drop_non_polish(df):\n",
        "    \"\"\"Detects and drops non-polish articles.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset containing non-polish articles.\n",
        "\n",
        "    Returns:\n",
        "        df (pd.Dataframe): News dataset containing only polish articles.\n",
        "    \"\"\"\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['Text']\n",
        "        detector = Detector(text, quiet=True)\n",
        "        if not (detector.language.name == 'Polish' and \n",
        "                detector.language.confidence >= 70):\n",
        "            df.drop([index], inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def drop_unidentified(df):\n",
        "    \"\"\"Drops news with 'unidentified' verdict.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset containing 'unidentified' news.\n",
        "\n",
        "    Returns:\n",
        "        pd.Dataframe: News dataset containing only fake or real news.\n",
        "    \"\"\"\n",
        "    return df[df['Verdict'] != 'unidentified']\n",
        "\n",
        "\n",
        "def drop_twitter(df):\n",
        "    \"\"\"Drops news from twitter containing some website elements.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset containing news with some website elements.\n",
        "\n",
        "    Returns:\n",
        "        pd.Dataframe: News dataset without noisy twitter news.\n",
        "    \"\"\"\n",
        "    return df[df['Text'].str.contains('Nowy na Twitterze')==False]\n",
        "\n",
        "\n",
        "def change_verdict_dtype(df):\n",
        "    \"\"\"Changes data type of 'Verdict' column to boolean.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset.\n",
        "\n",
        "    Returns:\n",
        "        df (pd.Dataframe): News dataset with boolean 'Verdict' column.\n",
        "    \"\"\"\n",
        "    df['Verdict'].replace('false', 0, inplace=True)\n",
        "    df['Verdict'].replace('true', 1, inplace=True),\n",
        "    df['Verdict'] = df['Verdict'].astype(bool)\n",
        "    return df\n",
        "\n",
        "\n",
        "def drop_short(df):\n",
        "    \"\"\"Drops articles shorter than 30 characters.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.Dataframe: News dataset with articles not shorter than 30 chars.\n",
        "    \"\"\"\n",
        "    return df[df['Text'].apply(len) >= 30]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fake news dataset\n",
        "df_fake = pd.read_excel('fakehunter_dataset.xlsx')\n",
        "\n",
        "df_fake = drop_title_and_url(df_fake)\n",
        "df_fake = drop_empty(df_fake)\n",
        "df_fake = drop_unidentified(df_fake)\n",
        "df_fake = drop_non_polish(df_fake)\n",
        "df_fake = drop_twitter(df_fake)"
      ],
      "metadata": {
        "id": "eVz80XO2C4ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load reliable news dataset\n",
        "df_real = pd.read_excel('termedia_dataset.xlsx')\n",
        "\n",
        "df_real = drop_title_and_url(df_real)\n",
        "df_real = drop_empty(df_real)"
      ],
      "metadata": {
        "id": "_2vmunlMDE-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create complete dataset (containing both fake and real news) and reset index\n",
        "df = pd.concat([df_fake, df_real])\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df = change_verdict_dtype(df)\n",
        "\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "m1sfD_TvmhRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing"
      ],
      "metadata": {
        "id": "KNHfEjLKzRRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_escape_chars(text: str) -> str:\n",
        "    \"\"\"Replaces escape characters with single whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    ret_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def strip_non_polish(text: str) -> str:\n",
        "    \"\"\"Replaces non-polish characters with single whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    reg = re.compile('[^a-zA-ZĄąĆćĘęŁłŃńÓóŚśŹźŻż]')\n",
        "    ret_text = reg.sub(' ', text)\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def replace_whitespace(text: str) -> str:\n",
        "    \"\"\"Replaces multiple whitespaces with single whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    reg = re.compile('\\s+')\n",
        "    ret_text = reg.sub(' ', text)\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def lowercase_all(text: str) -> str:\n",
        "    \"\"\"Converts case of article.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    ret_text = str.lower(text)\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    \"\"\"Performs tokenization by splitting articles into words.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    ret_text = str.split(text)\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def delete_stop_words(text: str) -> List[str]:\n",
        "    \"\"\"Removes stopwords.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input article containing stopwords.\n",
        "\n",
        "    Returns:\n",
        "        ret_text (str): Processed article.\n",
        "    \"\"\"\n",
        "    stop_words_txt = open('stopwords.txt')\n",
        "    stop_words = stop_words_txt.read().split('\\n')\n",
        "    stop_words_txt.close()\n",
        "    ret_text = [word for word in text if word not in stop_words]\n",
        "    return ret_text\n",
        "\n",
        "\n",
        "def lemmatize(df):\n",
        "    \"\"\"Performs lemmatization of articles in dataset.\n",
        "\n",
        "    Args:\n",
        "        df (pd.Dataframe): News dataset.\n",
        "\n",
        "    Returns:\n",
        "        df (pd.Dataframe): Lemmatized news dataset.\n",
        "    \"\"\"\n",
        "    morf = morfeusz2.Morfeusz()\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['Text']\n",
        "        lemm_words = []\n",
        "        for word in text:\n",
        "            _, _, interpretation = morf.analyse(word)[0]\n",
        "            lem_word = interpretation[1]\n",
        "            lem_word_stripped = lem_word.split(':', 1)[0].lower()\n",
        "            lemm_words.append(lem_word_stripped)\n",
        "        df.loc[index, 'Text'] = ' '.join(lemm_words)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "Y375IeUQIxY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text'] = df['Text'].apply(delete_escape_chars)\n",
        "df['Text'] = df['Text'].apply(strip_non_polish)\n",
        "df['Text'] = df['Text'].apply(replace_whitespace)\n",
        "df['Text'] = df['Text'].apply(lowercase_all)\n",
        "df['Text'] = df['Text'].apply(tokenize)\n",
        "df['Text'] = df['Text'].apply(delete_stop_words)\n",
        "\n",
        "df = lemmatize(df)"
      ],
      "metadata": {
        "id": "zXP_oECpL5iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head())\n",
        "\n",
        "df = drop_empty(df)\n",
        "df = drop_short(df)\n",
        "\n",
        "# Display number of fake and real news\n",
        "print(f'Number of fake news: \\t' + str(len(df[df['Verdict'] == False])))\n",
        "print(f'Number of real news: \\t' + str(len(df[df['Verdict'] == True])))\n",
        "print(f'Total number of news: \\t' + str(len(df)))\n",
        "\n",
        "# Export complete dataset\n",
        "df.to_excel('complete_dataset.xlsx', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "bzk9TE24qFXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "840a4b68-36a3-4178-84b8-05fca767c3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b2e6b7c-61ec-412c-b392-8e6213dbd6aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Verdict</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>nieoczywisty rzeczywistość fsychologia pozytyw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>bęcwalstwo polski nauka odkryty rpa nowy wirus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>magmag zaczęlo wyłączać serce sportowiec cały ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>omikron atakować kłamstwo kowidowych jednyn sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>głowny portal zdrowie jeszu wiara yeshu ang fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b2e6b7c-61ec-412c-b392-8e6213dbd6aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b2e6b7c-61ec-412c-b392-8e6213dbd6aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b2e6b7c-61ec-412c-b392-8e6213dbd6aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Verdict                                               Text\n",
              "0    False  nieoczywisty rzeczywistość fsychologia pozytyw...\n",
              "1    False  bęcwalstwo polski nauka odkryty rpa nowy wirus...\n",
              "2    False  magmag zaczęlo wyłączać serce sportowiec cały ...\n",
              "3    False  omikron atakować kłamstwo kowidowych jednyn sp...\n",
              "4    False  głowny portal zdrowie jeszu wiara yeshu ang fi..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of fake news: \t753\n",
            "Number of real news: \t1487\n",
            "Total number of news: \t2240\n"
          ]
        }
      ]
    }
  ]
}